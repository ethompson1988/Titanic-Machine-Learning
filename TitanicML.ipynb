{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "gender = pd.read_csv('gender_submission.csv')\n",
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Right off the bat we can see that PassengerId and Name will not have any value and Cabin is missing too many values, Ticket is too hard to ....\n",
    "solution_df = pd.DataFrame(test['PassengerId'])\n",
    "train = train.drop(['PassengerId','Name','Cabin','Ticket'], axis=1)\n",
    "test = test.drop(['PassengerId','Name','Cabin','Ticket'], axis=1)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()\n",
    "# train['Pclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, drop_first = True, columns = ['Sex','Embarked','Pclass'])\n",
    "test = pd.get_dummies(test, drop_first = True, columns = ['Sex','Embarked','Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have all numeric values, we can plot the correlation coefficient\n",
    "correlation = train.corr(method='pearson')\n",
    "# sns.heatmap(correlation,annot=True)\n",
    "# plt.show()\n",
    "# Pearson model says that .3-.49 indicates moderate correlation and .50-1 indicates strong correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(train['Age'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(train['Fare'],bins=40)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "train['Age'] = imp.fit_transform(train['Age'].values.reshape(-1,1))\n",
    "test['Age'] = imp.fit_transform(test['Age'].values.reshape(-1,1))\n",
    "test['Fare'] = imp.fit_transform(test['Fare'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()\n",
    "# test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "train['Age'] = scaler.fit_transform(train['Age'].values.reshape(-1,1))\n",
    "train['Fare'] = scaler.fit_transform(train['Fare'].values.reshape(-1,1))\n",
    "test['Age'] = scaler.fit_transform(test['Age'].values.reshape(-1,1))\n",
    "test['Fare'] = scaler.fit_transform(test['Age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = train.drop('Survived', axis=1)\n",
    "y_train = train['Survived']\n",
    "X_test  = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# model = LogisticRegression()\n",
    "# solvers = ['newton-cg', 'lbfgs','liblinear','sag', 'saga']\n",
    "# penalty = ['l1','l2','elasticnet']\n",
    "# c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(C=.1,penalty='l2',solver='newton-cg')\n",
    "# model.fit(X_train,y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# logreg_solution = solution_df.copy()\n",
    "# logreg_solution['Survived'] = predictions\n",
    "# logreg_solution.to_csv('logreg_et.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# model = RidgeClassifier()\n",
    "# alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# grid = dict(alpha=alpha)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RidgeClassifier(alpha=.2)\n",
    "# model.fit(X_train,y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# ridge_solution = solution_df.copy()\n",
    "# ridge_solution['Survived'] = predictions\n",
    "# ridge_solution.to_csv('ridge_et.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# model = KNeighborsClassifier()\n",
    "# n_neighbors = range(1, 21, 2)\n",
    "# weights = ['uniform', 'distance']\n",
    "# metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "# grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KNeighborsClassifier(metric='manhattan',n_neighbors=15,weights='uniform')\n",
    "# model.fit(X_train,y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# knn_solution = solution_df.copy()\n",
    "# knn_solution['Survived'] = predictions\n",
    "# knn_solution.to_csv('knn_et',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# model = SVC()\n",
    "# kernel = ['poly', 'rbf', 'sigmoid']\n",
    "# C = [50, 10, 1.0, 0.1, 0.01]\n",
    "# gamma = ['scale']\n",
    "# grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SVC(C=50,gamma='scale',kernel = 'rbf')\n",
    "# model.fit(X_train,y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# svc_solution = solution_df.copy()\n",
    "# svc_solution['Survived'] = predictions\n",
    "# svc_solution.to_csv('svc_et.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.817790 using {'n_estimators': 100}\n",
      "0.809942 (0.035514) with: {'n_estimators': 10}\n",
      "0.817790 (0.036751) with: {'n_estimators': 100}\n",
      "0.816288 (0.034322) with: {'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = BaggingClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "grid = dict(n_estimators=n_estimators)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "bagging_solution = solution_df.copy()\n",
    "bagging_solution['Survived'] = predictions\n",
    "bagging_solution.to_csv('bagging_solution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# n_estimators = [10, 100, 1000]\n",
    "# max_features = ['sqrt', 'log2']\n",
    "# grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(max_features = 'sqrt', n_estimators = 1000)\n",
    "# model.fit(X_train, y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# forest_solution = solution_df.copy()\n",
    "# forest_solution['Survived'] = predictions\n",
    "# forest_solution.to_csv('forest_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier()\n",
    "# n_estimators = [10, 100, 1000]\n",
    "# learning_rate = [0.001, 0.01, 0.1]\n",
    "# subsample = [0.5, 0.7, 1.0]\n",
    "# max_depth = [3, 7, 9]\n",
    "# grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GradientBoostingClassifier(learning_rate = 0.001, max_depth = 9, n_estimators = 1000, subsample = 0.7)\n",
    "# model.fit(X_train, y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# gradient_solution = solution_df.copy()\n",
    "# gradient_solution['Survived'] = predictions\n",
    "# gradient_solution.to_csv('gradient_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
