{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "gender = pd.read_csv('gender_submission.csv')\n",
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Right off the bat we can see that PassengerId and Name will not have any value and Cabin is missing too many values, Ticket is too hard to ....\n",
    "solution_df = pd.DataFrame(test['PassengerId'])\n",
    "train = train.drop(['PassengerId','Name','Cabin','Ticket'], axis=1)\n",
    "test = test.drop(['PassengerId','Name','Cabin','Ticket'], axis=1)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()\n",
    "# train['Pclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, drop_first = True, columns = ['Sex','Embarked','Pclass'])\n",
    "test = pd.get_dummies(test, drop_first = True, columns = ['Sex','Embarked','Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have all numeric values, we can plot the correlation coefficient\n",
    "correlation = train.corr(method='pearson')\n",
    "# sns.heatmap(correlation,annot=True)\n",
    "# plt.show()\n",
    "# Pearson model says that .3-.49 indicates moderate correlation and .50-1 indicates strong correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(train['Age'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(train['Fare'],bins=40)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "train['Age'] = imp.fit_transform(train['Age'].values.reshape(-1,1))\n",
    "test['Age'] = imp.fit_transform(test['Age'].values.reshape(-1,1))\n",
    "test['Fare'] = imp.fit_transform(test['Fare'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()\n",
    "# test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "train['Age'] = scaler.fit_transform(train['Age'].values.reshape(-1,1))\n",
    "train['Fare'] = scaler.fit_transform(train['Fare'].values.reshape(-1,1))\n",
    "test['Age'] = scaler.fit_transform(test['Age'].values.reshape(-1,1))\n",
    "test['Fare'] = scaler.fit_transform(test['Age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = train.drop('Survived', axis=1)\n",
    "y_train = train['Survived']\n",
    "X_test  = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# model = LogisticRegression()\n",
    "# solvers = ['newton-cg', 'lbfgs','liblinear','sag', 'saga']\n",
    "# penalty = ['l1','l2','elasticnet']\n",
    "# c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = LogisticRegression(C=.1,penalty='l2',solver='newton-cg')\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "logreg_solution = solution_df.copy()\n",
    "logreg_solution['Survived'] = predictions\n",
    "logreg_solution.to_csv('logreg_et.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# model = RidgeClassifier()\n",
    "# alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# grid = dict(alpha=alpha)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "model = RidgeClassifier(alpha=.2)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "ridge_solution = solution_df.copy()\n",
    "ridge_solution['Survived'] = predictions\n",
    "ridge_solution.to_csv('ridge_et.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# model = KNeighborsClassifier()\n",
    "# n_neighbors = range(1, 21, 2)\n",
    "# weights = ['uniform', 'distance']\n",
    "# metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "# grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(metric='manhattan',n_neighbors=15,weights='uniform')\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "knn_solution = solution_df.copy()\n",
    "knn_solution['Survived'] = predictions\n",
    "knn_solution.to_csv('knn_et',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# model = SVC()\n",
    "# kernel = ['poly', 'rbf', 'sigmoid']\n",
    "# C = [50, 10, 1.0, 0.1, 0.01]\n",
    "# gamma = ['scale']\n",
    "# grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(C=50,gamma='scale',kernel = 'rbf')\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "svc_solution = solution_df.copy()\n",
    "svc_solution['Survived'] = predictions\n",
    "svc_solution.to_csv('svc_et.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# model = BaggingClassifier()\n",
    "# n_estimators = [10, 100, 1000]\n",
    "# grid = dict(n_estimators=n_estimators)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = BaggingClassifier(n_estimators = 100)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "bagging_solution = solution_df.copy()\n",
    "bagging_solution['Survived'] = predictions\n",
    "bagging_solution.to_csv('bagging_solution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# n_estimators = [100, 200, 500, 750, 1000]\n",
    "# max_depth = [3, 5, 7, 9]\n",
    "# min_child_weight = [1, 3, 5]\n",
    "# # gamma = [i/10.0 for i in range(0,5)]\n",
    "# # subsample = [i/10.0 for i in range(6,10)]\n",
    "# # colsample_bytree = [i/10.0 for i in range(6,10)]\n",
    "# # reg_alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1, 1]\n",
    "# learning_rate = [0.01, 0.02, 0.05, 0.1]\n",
    "# max_features = ['sqrt', 'log2']\n",
    "# grid = dict(n_estimators=n_estimators, max_depth = max_depth, min_child_weight = min_child_weight, max_features=max_features)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_features = 'sqrt', n_estimators = 1000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "forest_solution = solution_df.copy()\n",
    "forest_solution['Survived'] = predictions\n",
    "forest_solution.to_csv('forest_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier()\n",
    "# n_estimators = [10, 100, 1000]\n",
    "# learning_rate = [0.001, 0.01, 0.1]\n",
    "# subsample = [0.5, 0.7, 1.0]\n",
    "# max_depth = [3, 7, 9]\n",
    "# grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(learning_rate = 0.001, max_depth = 9, n_estimators = 1000, subsample = 0.7)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "gradient_solution = solution_df.copy()\n",
    "gradient_solution['Survived'] = predictions\n",
    "gradient_solution.to_csv('gradient_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = {'logreg':logreg_solution['Survived'].values,\n",
    "             'ridge':ridge_solution['Survived'].values,\n",
    "             'knn':knn_solution['Survived'].values,\n",
    "             'svc':svc_solution['Survived'].values,\n",
    "             'bagging':bagging_solution['Survived'].values,\n",
    "             'forest':forest_solution['Survived'].values,\n",
    "             'gradient':gradient_solution['Survived'].values\n",
    "             }\n",
    "\n",
    "\n",
    "consensus_df = pd.DataFrame(data=solutions,index=solution_df['PassengerId'])\n",
    "\n",
    "# consensus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_df['confidence'] = sum([x for x in solutions.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_df['consensus'] = [0 if x < 4 else 1 for x in consensus_df['confidence'].values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg</th>\n",
       "      <th>ridge</th>\n",
       "      <th>knn</th>\n",
       "      <th>svc</th>\n",
       "      <th>bagging</th>\n",
       "      <th>forest</th>\n",
       "      <th>gradient</th>\n",
       "      <th>confidence</th>\n",
       "      <th>consensus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             logreg  ridge  knn  svc  bagging  forest  gradient  confidence  \\\n",
       "PassengerId                                                                   \n",
       "892               0      0    0    0        0       0         0           0   \n",
       "893               0      0    1    1        0       0         0           2   \n",
       "894               0      0    0    0        0       0         0           0   \n",
       "895               0      0    0    0        0       0         0           0   \n",
       "896               0      1    0    0        1       1         1           4   \n",
       "...             ...    ...  ...  ...      ...     ...       ...         ...   \n",
       "1305              0      0    0    0        0       0         0           0   \n",
       "1306              1      1    1    1        1       1         1           7   \n",
       "1307              0      0    0    0        1       0         0           1   \n",
       "1308              0      0    0    0        0       0         0           0   \n",
       "1309              0      0    0    0        1       1         0           2   \n",
       "\n",
       "             consensus  \n",
       "PassengerId             \n",
       "892                  0  \n",
       "893                  0  \n",
       "894                  0  \n",
       "895                  0  \n",
       "896                  1  \n",
       "...                ...  \n",
       "1305                 0  \n",
       "1306                 1  \n",
       "1307                 0  \n",
       "1308                 0  \n",
       "1309                 0  \n",
       "\n",
       "[418 rows x 9 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_solution = consensus_df.drop(['logreg','ridge','knn','svc','bagging','forest','gradient','confidence'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_solution = consensus_solution.rename(columns = {'consensus':'Survived'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 0\n",
       "894                 0\n",
       "895                 0\n",
       "896                 1\n",
       "...               ...\n",
       "1305                0\n",
       "1306                1\n",
       "1307                0\n",
       "1308                0\n",
       "1309                0\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_solution.to_csv('consensus_solution.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    222\n",
       "7     75\n",
       "4     30\n",
       "1     27\n",
       "6     25\n",
       "3     14\n",
       "2     14\n",
       "5     11\n",
       "Name: confidence, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_df['confidence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
